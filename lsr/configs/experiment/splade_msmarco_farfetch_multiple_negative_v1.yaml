# @package _global_
defaults:
  - override /dataset@train_dataset: msmarco_farfetch_triplets_v1
  - override /loss: multiple_negative_loss 
  - override /model: splade

exp_name: splade_msmarco_farfetch_multiple_negative_v1

data_collator:
  _target_: lsr.datasets.data_collator.DataCollator

tokenizer:
  tokenizer_name: distilbert-base-uncased

loss:
  q_regularizer: 
    _target_: lsr.losses.regularizer.FLOPs
    weight: 0.01
    T: 50000
  d_regularizer:
    _target_: lsr.losses.regularizer.FLOPs
    weight: 0.05
    T: 50000

training_arguments:
  dataloader_num_workers: 16 
  dataloader_drop_last: True
  per_device_train_batch_size: 4
  gradient_accumulation_steps: 2
  fp16: True 
  warmup_ratio: 0.1
  warmup_steps: 0
  learning_rate: 5e-6
  max_steps: -1
  num_train_epochs: 5
  save_steps: 10000
  save_total_limit: 10
  logging_steps: 100  

